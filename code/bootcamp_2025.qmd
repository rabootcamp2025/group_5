---
title: "bootcamp"
format:
  html:
    toc: true
    number_sections: true
    toc_float: true
    df_print: paged
    embed-resources: true
    self-contained: true

execute:
  echo: true
  warning: true
---

## Part1




進捗報告

count_country_mention.pyのコードを参考に、移民に関する演説の本文から国の言及回数を集計した。

当初Pythonコードを一行ずつ解析して、Rのコードに変換するように試みた。Pythonコードに慣れている人がおらず、なかなか概要把握に時間がかかった。

データの環境設定や構築に手間がかかった上に、分析をするにあたり、テキスト分析を初めて実践する者が大半だったため、全体像を把握するのに苦労した。




### 準備

```{r}
#| echo: false
#| warning: false


library(tidyverse)
library(quanteda)
library(jsonlite)
library(readtext)
library(here)
library(quanteda.textplots)
library(stopwords)


```

### データのインポート

```{r}
speeches_df <- 
  stream_in(file(here("data/data/speeches/Congress/imm_segments_with_tone_and_metadata.jsonlist")), 
                         verbose = FALSE)%>%
  mutate(doc_id = paste0("doc_", row_number()))
```


### 辞書の作成

```{r}
countries <- list('Ireland'= ('Ireland'),
  'Germany'= ('Germany'),
  'Mexico'= ('Mexico'),
  'Italy'= ('Italy'),
  'England'= ('England'),
  'Canada'= ('Canada'),
  'Russia'= c('Russia', 'USSR'),
  'Poland'= ('Poland'),
  'China'= ('China'),
  'India'= ('India'),
  'Sweden'= ('Sweden'),
  'Austria'= ('Austria'),
  'Philippines'= c('Philippines', 'Philippine'),
  'Cuba'= ('Cuba'),
  'Hungary'= ('Hungary'),
  'Norway'= ('Norway'),
  'Czechoslovakia'= c('Czechoslovakia', 'Czech', 'Slovakia', 'Slovak'),
  'Vietnam'= ('Vietnam'),
  'Scotland'= ('Scotland'),
  'El Salvador'= ('El Salvador'),
  'Korea'= ('Korea'),
  'France'= ('France'),
  'Dominican Republic'= ('Dominican'),
  'Guatemala'= ('Guatemala'),
  'Greece'= ('Greece'),
  'Colombia'= ('Colombia'),
  'Jamaica'= ('Jamaica'),
  'Yugoslavia'= c('Yugoslavia', 'Serbia', 'Croatia', 'Macedonia', 'Bosnia', 'Herzegovina', 'Montenegro'),
  'Honduras'= ('Honduras'),
  'Japan'= ('Japan'),
  'Haiti'= ('Haiti'),
  'Portugal'= ('Portugal'),
  'Denmark'= ('Denmark'),
  'Lithuania'= ('Lithuania'),
  'Switzerland'= ('Switzerland'),
  'Wales'= ('Wales'),
  'Taiwan'= ('Taiwan'),
  'Netherlands'= c('Netherlands', 'Holland'),
  'Brazil'= ('Brazil'),
  'Finland'= ('Finland'),
  'Iran'= ('Iran'),
  'Ecuador'= ('Ecuador'),
  'Venezuela'= ('Venezuela'),
  'Romania'= c('Romania', 'Rumania', 'Roumania'),
  'Peru'= ('Peru')
)
```

### 小文字化

```{r}
countries <- map(countries, tolower)
```


### 辞書化・コーパス化・合計集計

```{r}
countries_dic <- dictionary(countries)
```

```{r}
# コーパス化
corpus_sample <- corpus(speeches_df)

# トークン化
tokens_sample <- tokens(corpus_sample)

# トークン化したデータと国名辞書のマッチング
lookup_sample <- tokens_lookup(tokens_sample, countries_dic)

# DFM化
mention_dfm <- dfm(lookup_sample)

#合計集計
result_sample <- colSums(mention_dfm)
result_sample_df <- as.data.frame(result_sample)
result_sample_df_2 <- attributes(result_sample_df)
result_sample_df <- result_sample_df %>%
  mutate(country = result_sample_df_2$row.names)
```


### グラフの作成
```{r}
graph1 <- result_sample_df %>%
  ggplot(aes(x= reorder(country,result_sample),y = result_sample))+
  #scale_y_discrete(limit = factor(result_sample)) +
  geom_col()+
  coord_cartesian(xlim= c(0,16000))


graph1 <- result_sample_df %>%
  ggplot(aes(x= reorder(country,result_sample),y = result_sample))+
  geom_col()+
  coord_flip()+
  labs(title = "国名言及回数") +
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        )
graph1


```

## part.2
これよりも下はhein_bound_immのデータをトークン化し、単語の言及回数をプロットしようと試みた。


### スピーチデータを読み込む
```{r}
speeches_path <- list.files(here("data/hein_bound_imm"), pattern = "^speeches", full.names = TRUE)
descr_path <- list.files(here("data/hein_bound_imm"), pattern = "^descr", full.names = TRUE)


library(readr)

# テキストファイルを読み込む
speech_delim <- function(x){read_delim(x, delim = "|", 
                 col_names = c("doc_id", "text"),
                 quote = "", trim_ws = TRUE)}

speeches_list <- map(speeches_path, speech_delim)


descr_delim <- function(x){read_delim(x, delim = "|", 
                 col_names = c("doc_id", "text"),
                 quote = "", trim_ws = TRUE)}
descr_list <- map(descr_path, descr_delim)

speech <- do.call(rbind,speeches_list)

descr <- do.call(rbind,descr_list) %>% 
  rename(tag = text)

speech_data <- left_join(speech, descr, by = "doc_id")
speech_data <- speech_data %>%
  filter(X3 != 18940614)

```

### コーパス化とトークン化

```{r}
speech_corpus <- corpus(speech_data)

# 文書 → 文 に分割
speech_sentences <- corpus_reshape(speech_corpus, to = "sentences")

# 文 → 単語 にトークン化
speech_tokens <- tokens(speech_sentences, what = "word")
```

### 共起ネットワーク

グラフをプロットしようとしたが、できなかった。
```{r}
#| eval: false
#| 
a <- speech_tokens %>%
  quanteda::tokens_remove(stopwords(language = "en"), valuetype = "fixed") %>%
  quanteda::dfm() %>%
  quanteda::dfm_trim(min_termfreq = 4992L) %>%
  quanteda::fcm() %>%
  quanteda.textplots::textplot_network()
```




### トーンファイルの読み込み
```{r}
tone_df <- read.delim("G:/workings/group_5/data/data/speeches/Congress/imm_speech_ids_with_tone.tsv")

procedural_df <- read.delim("G:/workings/group_5/data/data/speeches/Congress/procedural_speech_ids.txt")

periods <- tribble(
  ~start, ~end, ~party, ~president, ~name,
  1869, 1877, 'R', 'Ulysses S. Grant', 'Grant',
           1877, 1881, 'R', 'Rutherford B. Hayes', 'Hayes',
           1881, 1885, 'R', 'Chester A. Arthur', 'Arther',
           1885, 1889, 'D', 'Grover Cleveland (85-89)', 'Cleveland',
           1889, 1893, 'R', 'Benjamin Harrison', 'Harrison',
           1893, 1897, 'D', 'Grover Cleveland (93-97)', 'Cleveland',
           1897, 1902, 'R', 'William McKinley', 'McKinley',
           1902, 1909, 'R', 'Theodore Roosevelt', 'Roosevelt',
           1909, 1913, 'R', 'William Howard Taft', 'Taft,',
           1913, 1921, 'D', 'Woodrow Wilson', 'Wilson',
           1921, 1924, 'R', 'Warren G. Harding', 'Harding',
           1924, 1929, 'R', 'Calvin Coolidge', 'Coolidge',
           1929, 1933, 'R', 'Herbert Hoover', 'Hoover',
           1933, 1945, 'D', 'Franklin D. Roosevelt', 'FDR',
           1945, 1953, 'D', 'Harry S. Truman', 'Truman',
           1953, 1961, 'R', 'Dwight D. Eisenhower', 'Eisenhower',
           1961, 1964, 'D', 'John F. Kennedy', 'Kennedy',
           1964, 1969, 'D', 'Lyndon B. Johnson', 'Johnson',
           1969, 1975, 'R', 'Richard Nixon', 'Nixon',
           1975, 1977, 'R', 'Gerald R. Ford', 'Ford',
           1977, 1981, 'D', 'Jimmy Carter', 'Carter',
           1981, 1989, 'R', 'Ronald Reagan', 'Reagan',
           1989, 1993, 'R', 'George Bush', 'GWBush',
           1993, 2001, 'D', 'William J. Clinton', 'Clinton',
           2001, 2009, 'R', 'George W. Bush', 'GBush',
           2009, 2017, 'D', 'Barack Obama', 'Obama',
           2017, 2021, 'R', 'Donald J. Trump', 'Trump')


periods <- periods %>%
  bind_rows()
periods <- as.matrix(periods)
periods <- t(periods)
```

```{r}

```











